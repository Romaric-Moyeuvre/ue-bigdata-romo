{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BATCH - OpenWeatherMap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import minio\n",
    "import pyspark\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/variables.json\", \"r\") as file :\n",
    "    data = json.load(file)\n",
    "\n",
    "apikey = data[\"apikey\"]\n",
    "locations = data[\"locations\"]\n",
    "plants = data[\"plants\"]\n",
    "\n",
    "URL_timemachine = \"https://api.openweathermap.org/data/3.0/onecall/timemachine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url(lat, lon, dt, units=\"metric\") :\n",
    "    return URL_timemachine + \"?lat=%f&lon=%f&dt=%d&appid=%s&units=%s\"%(lat, lon, dt, apikey, units)\n",
    "\n",
    "def preprocess(data) :\n",
    "    res =  {\"lat\": data[\"lat\"], \"lon\": data[\"lon\"]}\n",
    "    res.update(data[\"data\"][0])\n",
    "    res.pop(\"weather\", None)\n",
    "    date = datetime.datetime.fromtimestamp(res[\"dt\"])\n",
    "    res[\"day\"] =  date.day\n",
    "    res[\"month\"] = date.month\n",
    "    res[\"year\"] = date.year\n",
    "    res[\"hour\"] = date.hour\n",
    "    res[\"minute\"] = date.minute\n",
    "    return res\n",
    "\n",
    "def fetch(url) :\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200 :\n",
    "        data = response.json()\n",
    "        return preprocess(data)\n",
    "    else :\n",
    "        return None\n",
    "\n",
    "def collect(location = locations[\"nantes\"], hours = range(8, 19), duration = 1, day_step = 1) :\n",
    "    day = datetime.date.today()\n",
    "    data = []\n",
    "    for i in range(duration) :\n",
    "        for hour in hours :\n",
    "            dt_utc = datetime.datetime(day.year, day.month, day.day, hour, 30)\n",
    "            unix_timestamp = int(dt_utc.timestamp())\n",
    "            data_i = fetch(url(location[\"lat\"], location[\"lon\"], unix_timestamp))\n",
    "            if data_i :\n",
    "                data.append(data_i)\n",
    "        day = day + datetime.timedelta(days = - day_step)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf() \\\n",
    "    .setAppName('Naolib') \\\n",
    "    .setMaster('spark://spark:7077') \\\n",
    "    .set(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4\") \\\n",
    "    .set(\"spark.sql.shuffle.partitions\", \"10\")\n",
    "\n",
    "spark_context = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "sql_context = pyspark.sql.SQLContext(spark_context)\n",
    "\n",
    "spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"root\")\n",
    "spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"password\")\n",
    "spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark_context._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "\n",
    "minio_client = minio.Minio(\n",
    "    \"minio:9000\",\n",
    "    access_key=\"root\",\n",
    "    secret_key=\"password\",\n",
    "    secure=False\n",
    ")\n",
    "\n",
    "if not(minio_client.bucket_exists(\"weather\")):\n",
    "    minio_client.make_bucket(\"weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = collect(duration = 7*5)\n",
    "if data :\n",
    "    df = sql_context.read.json(spark_context.parallelize(data, 7))\n",
    "    df.select(\"*\").show()\n",
    "    df.select(\"day\", \"month\", \"year\", \"hour\", \"minute\", \"clouds\", \"temp\", \"feels_like\", \"humidity\", \"visibility\") \\\n",
    "        .withColumn(\"morning\", when(col(\"hour\") > 13, 1).otherwise(2)) \\\n",
    "        .withColumn(\"hash\", ((col(\"year\")*10000+col(\"month\"))*100+col(\"day\"))*10+col(\"morning\")) \\\n",
    "        .select(\"hash\", \"clouds\", \"temp\", \"feels_like\", \"humidity\", \"visibility\") \\\n",
    "        .groupBy([\"hash\"]) \\\n",
    "        .mean() \\\n",
    "        .select(\"hash\", \"avg(clouds)\", \"avg(temp)\", \"avg(feels_like)\", \"avg(humidity)\", \"avg(visibility)\") \\\n",
    "        .orderBy([\"hash\"]) \\\n",
    "        .show()\n",
    "else :\n",
    "    print(\"API Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = collect(duration = 365, day_step = 7)\n",
    "if data :\n",
    "    df = sql_context.read.json(spark_context.parallelize(data, 7))\n",
    "    df.select(\"month\", \"year\", \"clouds\", \"temp\", \"feels_like\", \"humidity\", \"visibility\") \\\n",
    "        .withColumn(\"hash\", col(\"year\")*100+col(\"month\")) \\\n",
    "        .select(\"hash\", \"clouds\", \"temp\", \"feels_like\", \"humidity\", \"visibility\") \\\n",
    "        .groupBy([\"hash\"]) \\\n",
    "        .mean() \\\n",
    "        .select(\"hash\", \"avg(clouds)\", \"avg(temp)\", \"avg(feels_like)\", \"avg(humidity)\", \"avg(visibility)\") \\\n",
    "        .orderBy([\"hash\"]) \\\n",
    "        .show()\n",
    "else :\n",
    "    print(\"API Error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
